{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85993d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_merged_summary=snakemake.input.merged_summary\n",
    "input_cluster_file=snakemake.input.cluster_file\n",
    "input_derreplicated_clusters=snakemake.input.derreplicated_clusters\n",
    "output_representatives=snakemake.output.representatives\n",
    "output_checkv_categories=snakemake.output.checkv_categories\n",
    "output_new_clusters=snakemake.output.new_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3218f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess the clustered_df DataFrame\n",
    "clustered_df = pd.read_csv(input_cluster_file, sep=\"\\t\", names=[\"rep\", \"mem\"])\n",
    "clustered_df[\"mem\"] = clustered_df[\"mem\"].str.split(\",\")\n",
    "clustered_df = clustered_df.explode('mem').reset_index(drop=True)\n",
    "\n",
    "# Read and preprocess the checkv_df_vOTUs DataFrame\n",
    "checkv_df_vOTUs = pd.read_csv(input_merged_summary, sep=\"\\t\",\n",
    "                            names= [\"contig_id_vOTU\", \"contig_length_vOTU\", \"provirus_vOTU\", \"proviral_length_vOTU\",\n",
    "                           \"gene_count_vOTU\", \"viral_genes_vOTU\", \"host_genes_vOTU\", \"checkv_quality_vOTU\",\n",
    "                           \"miuvig_quality_vOTU\", \"completeness_vOTU\", \"completeness_method_vOTU\",\n",
    "                           \"contamination_vOTU\", \"kmer_freq_vOTU\", \"warnings_vOTU\"])\n",
    "checkv_df_vOTUs = checkv_df_vOTUs[[\"contig_id_vOTU\", \"contig_length_vOTU\", \"checkv_quality_vOTU\",\n",
    "                                   \"completeness_vOTU\", \"provirus_vOTU\", \"warnings_vOTU\"]]\n",
    "checkv_df_vOTUs[\"contig_length_vOTU\"] = checkv_df_vOTUs[\"contig_length_vOTU\"].astype(float)\n",
    "checkv_df_vOTUs[\"completeness_vOTU\"] = checkv_df_vOTUs[\"completeness_vOTU\"].astype(float)\n",
    "checkv_df_vOTUs=checkv_df_vOTUs.groupby(\"contig_id_vOTU\").first().reset_index()\n",
    "\n",
    "# Create copies of the checkv_df_vOTUs DataFrame\n",
    "checkv_df_rep = checkv_df_vOTUs.copy()\n",
    "checkv_df_rep.columns = [\"contig_id_rep\", \"contig_length_rep\", \"checkv_quality_rep\", \"completeness_rep\",\n",
    "                         \"provirus_rep\", \"warnings_rep\"]\n",
    "\n",
    "# Merge DataFrames and drop unnecessary columns\n",
    "merged_df = clustered_df.merge(checkv_df_rep, left_on=\"rep\", right_on=\"contig_id_rep\", how=\"left\") \\\n",
    "                        .merge(checkv_df_vOTUs, left_on=\"mem\", right_on=\"contig_id_vOTU\", how=\"left\")\n",
    "merged_df = merged_df.drop(['contig_id_vOTU', 'contig_id_rep'], axis=1)\n",
    "merged_df[['completeness_vOTU', 'contig_length_vOTU', 'completeness_rep']] = merged_df[\n",
    "    ['completeness_vOTU', 'contig_length_vOTU', 'completeness_rep']].fillna(0)\n",
    "merged_df[\"completeness_vOTU\"] = merged_df[\"completeness_vOTU\"].astype(float)\n",
    "merged_df[\"contig_length_vOTU\"] = merged_df[\"contig_length_vOTU\"].astype(float)\n",
    "\n",
    "# Choose the contig with the highest completeness and the lowest contig length\n",
    "merged_df_best = merged_df[merged_df.groupby(['rep'], sort=False)['completeness_vOTU'].transform(max) == merged_df['completeness_vOTU']]\n",
    "merged_df_best = merged_df_best[merged_df_best.groupby(['rep'], sort=False)['contig_length_vOTU'].transform(min) == merged_df_best['contig_length_vOTU']]\n",
    "merged_df_best = merged_df_best.groupby(['rep']).first().reset_index()\n",
    "\n",
    "# Select final singletons and grouped contigs based on checkv quality\n",
    "final_singletons = merged_df_best[merged_df_best[\"rep\"] == merged_df_best[\"mem\"]][\"rep\"].tolist()\n",
    "\n",
    "merged_df_diff = merged_df_best[merged_df_best[\"rep\"] != merged_df_best[\"mem\"]]\n",
    "merged_df_diff = merged_df_diff.replace({'Complete': 4, 'High-quality': 3, 'Medium-quality': 2,'Low-quality': 1, 'Not-determined': 1})\n",
    "\n",
    "# Choose representatives based on checkv quality comparison\n",
    "merged_df_greatherthan = merged_df_diff[merged_df_diff[\"checkv_quality_rep\"] > merged_df_diff[\"checkv_quality_vOTU\"]]\n",
    "gr1 = merged_df_greatherthan[\"rep\"].tolist()\n",
    "\n",
    "merged_df_smallerthan = merged_df_diff[merged_df_diff[\"checkv_quality_rep\"] < merged_df_diff[\"checkv_quality_vOTU\"]]\n",
    "gr2 = merged_df_smallerthan[\"mem\"].tolist()\n",
    "\n",
    "merged_df_equal1 = merged_df_diff[(merged_df_diff[\"checkv_quality_rep\"] == merged_df_diff[\"checkv_quality_vOTU\"]) & \n",
    "                                       (merged_df_diff[\"warnings_rep\"]!=\"contig >1.5x longer than expected genome length\")]\n",
    "\n",
    "gr3 = merged_df_equal1[\"rep\"].tolist()\n",
    "\n",
    "merged_df_equal2 = merged_df_diff[(merged_df_diff[\"checkv_quality_rep\"] == merged_df_diff[\"checkv_quality_vOTU\"]) & \n",
    "                                       (merged_df_diff[\"warnings_rep\"]==\"contig >1.5x longer than expected genome length\")]\n",
    "gr4 = merged_df_equal2[merged_df_equal2[\"warnings_vOTU\"]==\"contig >1.5x longer than expected genome length\"][\"rep\"].tolist()\n",
    "\n",
    "gr5 = merged_df_equal2[merged_df_equal2[\"warnings_vOTU\"]!=\"contig >1.5x longer than expected genome length\"][\"mem\"].tolist()\n",
    "\n",
    "# merged_df_greatherthan.sort_values(by=\"contig_length_vOTU\")[-30:]\n",
    "representatives = final_singletons + gr1 + gr2 + gr3 +  gr4 + gr5\n",
    "final_df_rep = checkv_df_vOTUs[checkv_df_vOTUs['contig_id_vOTU'].isin(representatives)]\n",
    "\n",
    "# Sort the final_df_rep DataFrame by contig_length_vOTU column\n",
    "final_df_rep.sort_values(by=\"contig_length_vOTU\")                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_rep.groupby(\"checkv_quality_vOTU\").size().to_csv(output_checkv_categories, index=True, header=False)\n",
    "final_df_rep.groupby(\"checkv_quality_vOTU\").size().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263dd02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "derreplicated_df=pd.read_csv(input_derreplicated_clusters, sep=\"\\t\", names=[\"rep_d\", \"mem_d\"])\n",
    "derreplicated_df=derreplicated_df.merge(clustered_df, left_on=\"rep_d\", right_on=\"mem\")\n",
    "derreplicated_df=derreplicated_df[[\"rep\", \"mem_d\"]]\n",
    "# Make a copy of the original DataFrame `derreplicated_df` to avoid modifying it directly\n",
    "derreplicated_df_fixed = derreplicated_df.copy()\n",
    "\n",
    "# Create a set of unique values from the \"rep\" column in `derreplicated_df` for quick lookup\n",
    "rep_set = set(derreplicated_df[\"rep\"])\n",
    "\n",
    "# # Loop over each new reference (in `contig_id_vOTU` column) from `final_df_rep`\n",
    "for new_reference in final_df_rep[\"contig_id_vOTU\"]:\n",
    "    \n",
    "    # Check if the new reference is not already in the existing set of \"rep\" values\n",
    "    if new_reference not in rep_set:\n",
    "        \n",
    "        # Find the old reference in `derreplicated_df` where `mem` column matches the `new_reference`\n",
    "        # Get the corresponding value from the \"rep\" column\n",
    "        old_reference = derreplicated_df.loc[derreplicated_df[\"mem_d\"] == new_reference, \"rep\"].iloc[0]\n",
    "        \n",
    "        # Update `derreplicated_df_fixed` so that all occurrences of `old_reference` in \"rep\" are replaced by `new_reference`\n",
    "        derreplicated_df_fixed.loc[derreplicated_df_fixed[\"rep\"] == old_reference, \"rep\"] = new_reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89708148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep, group in derreplicated_df_fixed.groupby(\"rep\"):\n",
    "    # Check if `rep` does not start with \"P_\" or \"E_\"\n",
    "    if not rep.startswith(\"P_\") and not rep.startswith(\"E_\"):\n",
    "        \n",
    "        # Check if any value in the \"mem_d\" column starts with \"P_\" or \"E_\"\n",
    "        if group[\"mem_d\"].str.startswith(\"P_\").any() or group[\"mem_d\"].str.startswith(\"E_\").any():\n",
    "            \n",
    "            # Print the matching `rep` value\n",
    "            print(f\"Match found for rep: {rep}\")\n",
    "            \n",
    "            # Find values in \"mem_d\" that start with \"P_\" or \"E_\"\n",
    "            matching_mem_d = group[\"mem_d\"][group[\"mem_d\"].str.startswith(\"P_\") | group[\"mem_d\"].str.startswith(\"E_\")]\n",
    "            \n",
    "            # Collect `mem_d` and `contig_length_rep` pairs for sorting\n",
    "            mem_d_lengths = []\n",
    "            \n",
    "            # Loop over each matching mem_d value to get the corresponding contig length from checkv_df_rep\n",
    "            for mem_d in matching_mem_d:\n",
    "                # Find the contig length for each matching `mem_d` in `checkv_df_rep`\n",
    "                contig_length = checkv_df_rep.loc[checkv_df_rep[\"contig_id_rep\"] == mem_d, \"contig_length_rep\"]\n",
    "                if not contig_length.empty:\n",
    "                    mem_d_lengths.append((mem_d, contig_length.iloc[0]))\n",
    "\n",
    "            # Sort the list by `contig_length_rep` (second item in tuple)\n",
    "            mem_d_lengths.sort(key=lambda x: x[1])\n",
    "\n",
    "            # Print sorted `mem_d` values with their contig lengths\n",
    "            print(\"Matching mem_d values sorted by contig length:\")\n",
    "            for mem_d, length in mem_d_lengths:\n",
    "                print(f\"{mem_d}: {length}\")\n",
    "                \n",
    "            # Set new_reference as the longest (last in sorted list)\n",
    "            new_reference = mem_d_lengths[-1][0]  # Get only the `mem_d` part\n",
    "            print(\"new_reference:\", new_reference)\n",
    "            \n",
    "            # Replace the \"rep\" column values where \"rep\" == rep with new_reference\n",
    "            derreplicated_df_fixed.loc[derreplicated_df_fixed[\"rep\"] == rep, \"rep\"] = new_reference\n",
    "\n",
    "derreplicated_df_fixed.to_csv(output_new_clusters, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save representative contig IDs to a CSV file\n",
    "derreplicated_df_fixed[\"rep\"].to_csv(output_representatives, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c78af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "derreplicated_df_fixed.groupby(\"rep\").first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
