{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8840f571",
   "metadata": {},
   "source": [
    "# Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from scipy.optimize import curve_fit\n",
    "import json\n",
    "\n",
    "#------------------------------------------\n",
    "colours=[\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",\"#002626\",\"#337ca0\",\"#9d8df1\",\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",\"#002626\",\"#337ca0\",\"#9d8df1\",\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",\"#002626\",\"#337ca0\",\"#9d8df1\",\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",\"#002626\",\"#337ca0\",\"#9d8df1\",\"#679436\",\"#ffd400\",\"#d7907b\",\"#6c4b5e\",\"#87c38f\",\"#c6d8ff\",\"#9b1d20\",]\n",
    "\n",
    "\n",
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob, os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.5\n",
    "plt.rcParams[\"xtick.major.width\"] = 1.5\n",
    "plt.rcParams[\"ytick.major.width\"] = 1.5\n",
    "plt.rcParams[\"xtick.major.size\"] = 8\n",
    "plt.rcParams[\"ytick.major.size\"] = 8\n",
    "plt.rcParams[\"axes.titlepad\"] = 20\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams[\"axes.titlesize\"] = 30\n",
    "plt.rcParams['axes.labelsize'] = 23.5\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Liberation Sans']\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir=snakemake.params.clean_dir\n",
    "raw_dir=snakemake.params.raw_dir\n",
    "qc_dir=snakemake.params.qc_dir\n",
    "\n",
    "SAMPLES=list(snakemake.params.samples)\n",
    "forward_tag=\"_\" + snakemake.params.forward_tag\n",
    "reverse_tag=\"_\" + snakemake.params.reverse_tag\n",
    "\n",
    "input_histograms=list(snakemake.input.histograms)\n",
    "illumina_preqc=snakemake.input.preqc_txt\n",
    "illumina_postqc=snakemake.input.postqc_txt\n",
    "#------------------------------------------\n",
    "output_kmer_png=snakemake.output.kmer_png\n",
    "output_kmer_svg=snakemake.output.kmer_svg\n",
    "output_kmer_png_fitted=snakemake.output.kmer_fit_png\n",
    "output_kmer_svg_fitted=snakemake.output.kmer_fit_svg\n",
    "output_kmer_fit_html=snakemake.output.kmer_fit_html\n",
    "output_qc_summary_html=snakemake.output.qc_summary_html\n",
    "output_percentage_kept_reads_png=snakemake.output.percentage_kept_reads_png\n",
    "output_percentage_kept_reads_svg=snakemake.output.percentage_kept_reads_svg\n",
    "output_percentage_kept_Mbp_png=snakemake.output.percentage_kept_Mbp_png\n",
    "output_percentage_kept_Mbp_svg=snakemake.output.percentage_kept_Mbp_svg\n",
    "output_step_qc_reads_html=snakemake.output.step_qc_reads_html\n",
    "output_steps_qc_reads_png=snakemake.output.steps_qc_reads_png\n",
    "output_steps_qc_reads_svg=snakemake.output.steps_qc_reads_svg\n",
    "output_steps_qc_percentage_png=snakemake.output.steps_qc_percentage_png\n",
    "output_steps_qc_percentage_svg=snakemake.output.steps_qc_percentage_svg\n",
    "output_supperdedupper_html=snakemake.output.supperdedupper_html\n",
    "output_supperdedupper_png=snakemake.output.supperdedupper_png\n",
    "output_supperdedupper_svg=snakemake.output.supperdedupper_svg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a4b5394",
   "metadata": {},
   "source": [
    "## KMER rarefraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Sort input_histograms and print the sorted list\n",
    "input_histograms.sort()\n",
    "\n",
    "# Sort SAMPLES\n",
    "SAMPLES.sort()\n",
    "\n",
    "# Initialize n and read_max as 0\n",
    "n=0\n",
    "read_max=0\n",
    "\n",
    "# Loop through each histogram in input_histograms\n",
    "for h in input_histograms:\n",
    "    # Read the histogram file as a pandas dataframe\n",
    "    df=pd.read_csv(h, sep=\"\\t\")\n",
    "    \n",
    "    # Rename columns and select only the \"counts\" and \"percent\" columns\n",
    "    df.columns=[\"counts\", \"percent\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"rand_cnt\", \"j\"]\n",
    "    df=df[[\"counts\", \"percent\"]]\n",
    "    \n",
    "    # Convert percent to percentage of missing kmers and counts to millions of reads\n",
    "    df[\"percent\"]=(100-df[\"percent\"])\n",
    "    df[\"counts\"]=df[\"counts\"]/1000000\n",
    "    \n",
    "    # Plot the data as a line plot\n",
    "    ax = sns.lineplot(x=\"counts\", y=\"percent\", data=df,err_style='band',color=colours[n], label=h.split(\"/\")[-1].split(\"_kmer\")[0], linewidth=0.5)\n",
    "    \n",
    "    # Add a vertical line at the x-value corresponding to the maximum count and update read_max if needed\n",
    "    plt.axvline(df[\"counts\"].max(), 0,1, linestyle=\"--\", color=colours[n], alpha=0.3)\n",
    "    read_max=max(read_max,df[\"counts\"].max())\n",
    "    \n",
    "    # Increment n\n",
    "    n=n+1\n",
    "    \n",
    "    # Set y- and x-axis limits\n",
    "    ax.set(ylim=(0,110))\n",
    "    ax.set(xlim=(0, read_max*1.2))\n",
    "\n",
    "    # Set x- and y-axis labels and legend\n",
    "    ax.set_xlabel(\"Read count (Million reads)\")\n",
    "    ax.set_ylabel(\"Known k-mers (%)\")\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Save the figure as png and svg files\n",
    "    ax.figure.savefig(output_kmer_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "    ax.figure.savefig(output_kmer_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47494c0e",
   "metadata": {},
   "source": [
    "# KMER rarefraction log fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Define the number of million reads to trim\n",
    "trim_reads = 50\n",
    "\n",
    "# Initialize variables\n",
    "read_max = 0\n",
    "n = 0\n",
    "samples = []\n",
    "a_list = []\n",
    "b_list = []\n",
    "max_reads = []\n",
    "slope_list = []\n",
    "\n",
    "# Define the logarithmic function used for fitting\n",
    "def logFunc(x, a, b):\n",
    "    return a + b*np.log(x)\n",
    "\n",
    "# Loop through input histograms\n",
    "for h in input_histograms:\n",
    "    # Load the data from the current input histogram\n",
    "    df = pd.read_csv(h, sep=\"\\t\")\n",
    "    # Rename the columns to make them easier to work with\n",
    "    df.columns = [\"counts\", \"percent\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"rand_cnt\", \"j\"]\n",
    "    # Drop unused columns\n",
    "    df = df[[\"counts\", \"percent\"]]\n",
    "    # Calculate the percentage of known k-mers and convert the counts to millions of reads\n",
    "    df[\"percent\"] = (100 - df[\"percent\"])\n",
    "    df[\"counts\"] = df[\"counts\"] / 1000000\n",
    "    # Plot the original data\n",
    "    ax = sns.lineplot(x=\"counts\", y=\"percent\", data=df, err_style='band', color=colours[n], label=h.split(\"/\")[-1].split(\"_kmer\")[0], linewidth=0.5, alpha=0.8)\n",
    "    # Keep track of the maximum read count\n",
    "    read_max = max(read_max, df[\"counts\"].max())\n",
    "    # If there are enough data points, fit a logarithmic function to the tail of the data\n",
    "    if len(df[\"counts\"]) > trim_reads+1:\n",
    "        # Fit the function to the tail of the data\n",
    "        popt, pcov = curve_fit(logFunc, df[\"counts\"][trim_reads:], df[\"percent\"][trim_reads:])\n",
    "        # Plot the fitted function\n",
    "        ax = sns.lineplot(x=np.arange(0, trim_reads, 0.25), y=logFunc(np.arange(0, trim_reads, 0.25), *popt), color=colours[n], err_style='band', label=h.split(\"/\")[-1].split(\"_kmer\")[0] + \"_fit\", linewidth=0.5, alpha=0.5)\n",
    "        # Store the fitting parameters and other statistics\n",
    "        samples.append(h.split(\"/\")[-1].split(\"_kmer\")[0])\n",
    "        a_list.append(popt[0])\n",
    "        b_list.append(popt[1])\n",
    "        max_reads.append(df[\"counts\"].max())\n",
    "        reads_to_1 = ((popt[0]) / (popt[1]))\n",
    "        slope_list.append(popt[1] / df[\"counts\"].max())\n",
    "    # Add a vertical line to indicate the maximum read count\n",
    "    plt.axvline(df[\"counts\"].max(), 0, 1, linestyle=\"--\", color=colours[n], alpha=0.4)\n",
    "    # Increment the sample counter\n",
    "    n = n+1\n",
    "    \n",
    "# Set the limits of the x and y axes\n",
    "ax.set(ylim=(0, 110))\n",
    "ax.set(xlim=(0, read_max*1.5))\n",
    "\n",
    "# Set axis limits and labels, add legend, and save the figure\n",
    "ax.set(ylim=(0, 110))\n",
    "ax.set(xlim=(0, read_max*1.5))\n",
    "ax.set_xlabel(\"Read count (Million reads)\")\n",
    "ax.set_ylabel(\"Known k-mers (%)\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.figure.savefig(output_kmer_png_fitted, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "ax.figure.savefig(output_kmer_svg_fitted, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new empty pandas DataFrame\n",
    "stats_df=pd.DataFrame()\n",
    "\n",
    "# add columns to the DataFrame using lists\n",
    "stats_df[\"Sample\"]=samples\n",
    "stats_df[\"a\"]=a_list\n",
    "stats_df[\"b\"]=b_list\n",
    "stats_df[\"slope\"]=slope_list\n",
    "stats_df[\"M_reads\"]=max_reads\n",
    "stats_df[\"b_-_Mreads\"]=stats_df[\"b\"]-stats_df[\"M_reads\"]\n",
    "\n",
    "# sort the DataFrame by \"Sample\" column, apply background color gradient to it, and render it as an HTML table\n",
    "stats_df_out=stats_df.sort_values(by=\"Sample\").style.background_gradient(cmap=\"RdYlGn\").render()\n",
    "\n",
    "# write the HTML table to a file\n",
    "with open(output_kmer_fit_html,\"w\") as fp:\n",
    "    fp.write(stats_df_out)\n",
    "\n",
    "# sort the DataFrame by \"Sample\" column and apply background color gradient to it\n",
    "stats_df.sort_values(by=\"Sample\").style.background_gradient(cmap=\"RdYlGn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6395eef3",
   "metadata": {},
   "source": [
    "## PreQC and PostQC FASTQC statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9afa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre- and post-illumina sequencing quality control data into pandas dataframes\n",
    "preqc = pd.read_csv(illumina_preqc, sep=\"\\t\")\n",
    "postqc = pd.read_csv(illumina_postqc, sep=\"\\t\")\n",
    "\n",
    "# create a new dataframe with columns for Filename, average sequence length, and total sequences from the preqc dataframe\n",
    "read_stats_df1 = preqc[[\"Filename\",\"avg_sequence_length\", \"Total Sequences\"]]\n",
    "\n",
    "# calculate the total number of megabases for each file and add this as a new column to read_stats_df1\n",
    "read_stats_df1[\"Mbp\"] = read_stats_df1[\"avg_sequence_length\"] * read_stats_df1[\"Total Sequences\"] / 1000000\n",
    "\n",
    "# remove the \".fastq\" extension from the Filename column\n",
    "read_stats_df1[\"Filename\"] = read_stats_df1[\"Filename\"].str.split(\".fastq\").str[0]\n",
    "\n",
    "# rename the columns of read_stats_df1\n",
    "read_stats_df1.columns = [\"file_pre\",\"length_pre\", \"number_pre\", \"Mbp_pre\"]\n",
    "\n",
    "# set the Filename column as the index of read_stats_df1\n",
    "read_stats_df1 = read_stats_df1.set_index('file_pre')\n",
    "\n",
    "# remove any whitespace from the index values of read_stats_df1\n",
    "read_stats_df1.index = read_stats_df1.index.map(\"\".join)\n",
    "\n",
    "# create a new dataframe with columns for Filename, average sequence length, and total sequences from the postqc dataframe\n",
    "read_stats_df2 = postqc[[\"Filename\",\"avg_sequence_length\", \"Total Sequences\"]]\n",
    "\n",
    "# calculate the total number of megabases for each file and add this as a new column to read_stats_df2\n",
    "read_stats_df2[\"Mbp\"] = read_stats_df2[\"avg_sequence_length\"] * read_stats_df2[\"Total Sequences\"] / 1000000\n",
    "\n",
    "# replace certain portions of the Filename column with standard suffixes (e.g. _forward -> _R1)\n",
    "read_stats_df2[\"Filename\"] = read_stats_df2[\"Filename\"].str.replace(\"_forward\", \"_R1\")\n",
    "read_stats_df2[\"Filename\"] = read_stats_df2[\"Filename\"].str.replace(\"_reverse\", \"_R2\")\n",
    "read_stats_df2[\"Filename\"] = read_stats_df2[\"Filename\"].str.replace(\"_unpaired\", \"_U\")\n",
    "read_stats_df2[\"Filename\"] = read_stats_df2[\"Filename\"].str.split(\"_paired\").str[0]\n",
    "read_stats_df2[\"Filename\"] = read_stats_df2[\"Filename\"].str.split(\"_clean\").str[0]\n",
    "\n",
    "# create a new column in read_stats_df2 for the sample name, based on the first part of the Filename (before the final underscore)\n",
    "read_stats_df2[\"Sample\"] = read_stats_df2[\"Filename\"].str.rsplit(\"_\",1).str[0]\n",
    "\n",
    "# set the Filename column as the index of read_stats_df2\n",
    "read_stats_df2 = read_stats_df2.set_index('Filename')\n",
    "\n",
    "# rename the columns of read_stats_df2\n",
    "read_stats_df2.columns=[\"length_post\", \"number_post\", \"Mbp_post\", \"sample\"]\n",
    "\n",
    "# merge read_stats_df1 and read_stats_df2 on their indices (i.e. Filename), keeping all rows from both dataframes\n",
    "read_stats_df3 = read_stats_df1.merge(read_stats_df2, left_index=True, right_index=True, how=\"outer\")\n",
    "\n",
    "# replace any NaN (missing) values in read_stats_df3 with 0\n",
    "read_stats_df3 = read_stats_df3.fillna(0)\n",
    "\n",
    "# return the final merged dataframe\n",
    "read_stats_df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre quality control fastQC statistics\n",
    "preqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post quality control fastQC statistics\n",
    "postqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group read statistics by sample\n",
    "read_stats_df = read_stats_df3.groupby([\"sample\"]).sum()\n",
    "\n",
    "# Calculate percentage of reads and Mbp kept\n",
    "read_stats_df[\"%number_kept\"] = (read_stats_df[\"number_post\"] / read_stats_df[\"number_pre\"] * 100).round(2)\n",
    "read_stats_df[\"%Mbp_kept\"] = (read_stats_df[\"Mbp_post\"] / read_stats_df[\"Mbp_pre\"] * 100).round(2)\n",
    "\n",
    "# Calculate percentage of reads and Mbp removed\n",
    "read_stats_df[\"%Mbp_removed\"] = 100 - read_stats_df[\"%Mbp_kept\"]\n",
    "read_stats_df[\"%number_removed\"] = 100 - read_stats_df[\"%number_kept\"]\n",
    "\n",
    "# sort the DataFrame by \"Sample\" column, apply background color gradient to it, and render it as an HTML table\n",
    "read_stats_out=read_stats_df.drop([\"length_pre\", \"length_post\"], axis=1).style.background_gradient(cmap=\"RdYlGn\").render()\n",
    "\n",
    "# write the HTML table to a file\n",
    "with open(output_qc_summary_html,\"w\") as fp:\n",
    "    fp.write(stats_df_out)\n",
    "    \n",
    "# Drop unnecessary columns and apply a gradient color scheme to the resulting DataFrame\n",
    "read_stats_df.drop([\"length_pre\", \"length_post\"], axis=1).style.background_gradient(cmap=\"RdYlGn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60a7fd73",
   "metadata": {},
   "source": [
    "### Percentage of kept/removed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d15f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Define colors for the plot\n",
    "colors = sns.color_palette(\"Paired\", n_colors=2)\n",
    "\n",
    "# Calculate the figure width based on the number of samples\n",
    "fig_width = len(SAMPLES) * .4\n",
    "\n",
    "# Create a LinearSegmentedColormap object using the colors defined above\n",
    "cmap1 = LinearSegmentedColormap.from_list(\"my_colormap\", colors)\n",
    "\n",
    "# Create a bar plot of the percentage of reads kept and removed for each sample\n",
    "ax = read_stats_df[[\"%number_kept\",\"%number_removed\"]].plot(kind='bar', stacked=True, colormap=cmap1, figsize=(fig_width,12),width=0.8)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Add axis labels and a title to the plot\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Percentage of reads') \n",
    "plt.title('Percentage of kept reads')\n",
    "\n",
    "# Set the limits of the y axis\n",
    "ax.set(ylim=(0, 100))\n",
    "\n",
    "# Save the plot as a PNG and SVG file\n",
    "ax.figure.savefig(output_percentage_kept_reads_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "ax.figure.savefig(output_percentage_kept_reads_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9c3d6f",
   "metadata": {},
   "source": [
    "### Percentage of kept/removed Mbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "\n",
    "# set color palette for the bar chart\n",
    "colors = sns.color_palette(\"Paired\", n_colors=2)\n",
    "\n",
    "# set the width of the figure based on number of samples\n",
    "fig_width=len(SAMPLES) * .4\n",
    "\n",
    "# create a colormap from the color palette\n",
    "cmap1 = LinearSegmentedColormap.from_list(\"my_colormap\", colors)\n",
    "\n",
    "# create a stacked bar chart of percentage of Mbp kept and removed\n",
    "ax=read_stats_df[[\"%Mbp_kept\",\"%Mbp_removed\"]].plot(kind='bar', stacked=True,colormap=cmap1, figsize=(fig_width,12),width=0.8)\n",
    "\n",
    "# add a legend to the chart\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# add x and y axis labels to the chart\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Percentage of Mbp') \n",
    "\n",
    "# add a title to the chart\n",
    "plt.title('Percentage of kept Mpb', pad=20)\n",
    "\n",
    "# Set the limits of the y axis\n",
    "ax.set(ylim=(0, 100))\n",
    "\n",
    "# save the chart as a PNG and SVG file\n",
    "ax.figure.savefig(output_percentage_kept_Mbp_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "ax.figure.savefig(output_percentage_kept_Mbp_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1d011e",
   "metadata": {},
   "source": [
    "## Removed reads per QC step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b638e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists and variables\n",
    "sample_l=[]\n",
    "read_types=[]\n",
    "raw=[]\n",
    "trimmed=[]\n",
    "duk=[]\n",
    "euk=[]\n",
    "norm=[]\n",
    "reads=[]\n",
    "\n",
    "# Loop through each sample in read_stats_df and populate the lists with relevant information\n",
    "for sample in (read_stats_df.index.to_list()):  \n",
    "    # Add sample name and read type to lists\n",
    "    sample_l.extend([sample]*3)\n",
    "    read_types.extend([\"R1\", \"R2\", \"U\"])\n",
    "    # Read in raw read counts for each read type and add to raw list\n",
    "    raw.append(int(open(raw_dir + \"/\" + sample + forward_tag + \"_read_count.txt\" , 'r').readline().strip()))\n",
    "    raw.append(int(open(raw_dir + \"/\" +  sample + reverse_tag + \"_read_count.txt\" , 'r').readline().strip()))\n",
    "    raw.append(int(0))\n",
    "    # Read in trimmed read counts for each read type and add to trimmed list\n",
    "    trimmed.append(int(open(clean_dir + \"/\" + sample + \"_forward_paired_read_count.txt\" , 'r').readline().strip()))\n",
    "    trimmed.append(int(open(clean_dir + \"/\" + sample + \"_reverse_paired_read_count.txt\" , 'r').readline().strip()))\n",
    "    trimmed.append(int(open(clean_dir + \"/\" + sample + \"_merged_unpaired.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    # Read in non-eukaryotic read counts for each read type and add to euk list\n",
    "    euk.append(int(open(clean_dir + \"/\" + sample + \"_forward_paired_noEuk.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    euk.append(int(open(clean_dir + \"/\" + sample + \"_reverse_paired_noEuk.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    euk.append(int(open(clean_dir + \"/\" + sample + \"_unpaired_noEuk.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    # Read in BBDuk-cleaned read counts for each read type and add to duk list\n",
    "    duk.append(int(open(clean_dir + \"/\" + sample + \"_forward_paired_clean.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    duk.append(int(open(clean_dir + \"/\" + sample + \"_reverse_paired_clean.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    duk.append(int(open(clean_dir + \"/\" + sample + \"_unpaired_clean.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    # Read in normalized read counts for each read type and add to norm list\n",
    "    norm.append(int(open(clean_dir + \"/\" + sample + \"_forward_paired_norm.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    norm.append(int(open(clean_dir + \"/\" + sample + \"_reverse_paired_norm.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "    norm.append(int(open(clean_dir + \"/\" + sample + \"_unpaired_norm.tot_read_count.txt\" , 'r').readline().strip()))\n",
    "\n",
    "# Create an empty pandas DataFrame\n",
    "df_counts = pd.DataFrame()\n",
    "\n",
    "# Add columns to the DataFrame\n",
    "df_counts[\"sample\"] = sample_l\n",
    "df_counts[\"type\"] = read_types\n",
    "df_counts[\"raw\"] = raw\n",
    "df_counts[\"trimmomatic\"] = trimmed\n",
    "df_counts[\"kraken\"] = euk\n",
    "df_counts[\"bbduk\"] = duk\n",
    "df_counts[\"norm\"] = norm\n",
    "\n",
    "# Calculate values for new columns and add them to the DataFrame\n",
    "df_counts[\"raw_s\"] = df_counts[\"raw\"] / 1000000\n",
    "df_counts[\"low_QC_reads_s\"] = (df_counts[\"raw\"] - df_counts[\"trimmomatic\"]) / 1000000\n",
    "df_counts[\"eukaryotic_reads_s\"] = (df_counts[\"trimmomatic\"] - df_counts[\"kraken\"]) / 1000000\n",
    "df_counts[\"bbduk_phix174_reads_s\"] = (df_counts[\"kraken\"] - df_counts[\"bbduk\"]) / 1000000\n",
    "df_counts[\"duplicate_reads_s\"] = (df_counts[\"bbduk\"] - df_counts[\"norm\"]) / 1000000\n",
    "df_counts[\"assembly_reads_s\"] = df_counts[\"norm\"] / 1000000\n",
    "\n",
    "df_counts[\"low_QC_reads_p\"] = df_counts[\"low_QC_reads_s\"] / df_counts[\"raw_s\"]\n",
    "df_counts[\"eukaryotic_reads_p\"] = df_counts[\"eukaryotic_reads_s\"] / df_counts[\"raw_s\"]\n",
    "df_counts[\"bbduk_phix174_reads_p\"] = df_counts[\"bbduk_phix174_reads_s\"] / df_counts[\"raw_s\"]\n",
    "df_counts[\"duplicate_reads_p\"] = df_counts[\"duplicate_reads_s\"] / df_counts[\"raw_s\"]\n",
    "df_counts[\"assembly_reads_p\"] = df_counts[\"assembly_reads_s\"] / df_counts[\"raw_s\"]\n",
    "\n",
    "# Create a new column by concatenating two existing columns\n",
    "df_counts[\"sample_long\"] = df_counts[\"sample\"] + \"_\" + df_counts[\"type\"]\n",
    "\n",
    "# Convert the DataFrame to an HTML table and write it to a file\n",
    "df_counts.to_html(output_step_qc_reads_html)\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_counts\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70cee76c",
   "metadata": {},
   "source": [
    "### Number of kept/removed reads per QC step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set color palette and figure width\n",
    "colors = sns.color_palette(\"Paired\", n_colors=5)\n",
    "fig_width = len(SAMPLES) * 0.4\n",
    "\n",
    "# Define legend text and create colormap\n",
    "legend_text = [\"Used for assembly\", \"Duplicate (removed)\", \"phiX174 (user contaminants)\", \"Eukaryotic contamination\", \"Low quality\"]\n",
    "cmap1 = LinearSegmentedColormap.from_list(\"my_colormap\", colors)\n",
    "\n",
    "# Filter the dataframe to only include R1 reads and plot a stacked bar chart\n",
    "df_counts_paired = df_counts[df_counts[\"type\"] == \"R1\"]\n",
    "ax = df_counts_paired.plot(x=\"sample\", y=[\"assembly_reads_s\", \"duplicate_reads_s\", \"bbduk_phix174_reads_s\", \"eukaryotic_reads_s\", \"low_QC_reads_s\"], kind=\"bar\", stacked=True, colormap=cmap1, figsize=(fig_width, 12),width=0.8)\n",
    "\n",
    "# Add legend, axis labels, and save the figure\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Million reads\") \n",
    "plt.savefig(output_steps_qc_reads_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "plt.savefig(output_steps_qc_reads_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "973aff4a",
   "metadata": {},
   "source": [
    "### Percentage of kept/removed reads per QC step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Set colors for the stacked bar chart\n",
    "colors = sns.color_palette(\"Paired\", n_colors=5)\n",
    "\n",
    "# Set figure width based on number of samples\n",
    "fig_width = len(SAMPLES) * .4\n",
    "\n",
    "# Create a colormap\n",
    "cmap1 = LinearSegmentedColormap.from_list(\"my_colormap\", colors)\n",
    "\n",
    "# Select only R1 data from df_counts\n",
    "df_counts_paired = df_counts[df_counts[\"type\"] == \"R1\"]\n",
    "\n",
    "# Plot stacked bar chart with proportion of raw reads\n",
    "ax = df_counts_paired.plot(\n",
    "    x=\"sample\",\n",
    "    y=[\"assembly_reads_p\", \"duplicate_reads_p\", \"bbduk_phix174_reads_p\", \"eukaryotic_reads_p\", \"low_QC_reads_p\"],\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    colormap=cmap1,\n",
    "    figsize=(fig_width, 12),\n",
    "    width=0.8\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "legend_text = [\"Used for assembly\", \"Duplicate (removed)\", \"phiX174 (user contaminants)\", \"Eukaryotic contamination\", \"Low quality\"]\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set x and y labels\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Proportion of raw reads\")\n",
    "\n",
    "# Set the limits of the y axis\n",
    "ax.set(ylim=(0, 1))\n",
    "\n",
    "# Save the figure as PNG and SVG files\n",
    "plt.savefig(output_steps_qc_percentage_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "plt.savefig(output_steps_qc_percentage_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_paired"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857e48b9",
   "metadata": {},
   "source": [
    "## Super Deduper PCR duplication statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf59dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size and font scale for seaborn\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# initialize variables\n",
    "maxim=0\n",
    "n=0\n",
    "percentages=[]\n",
    "\n",
    "# loop through each sample\n",
    "for sample in SAMPLES:   \n",
    "    # open the file and load the data\n",
    "    f = open(qc_dir + \"/\" +sample + \"_stats_pcr_duplicates.log\")\n",
    "    data=json.load(f)\n",
    "    \n",
    "    # extract the relevant data and calculate percentage of duplicates\n",
    "    df=pd.DataFrame(data[0][\"Fragment\"][\"duplicate_saturation\"], columns=[\"reads\",\"dup\"] )/1000000\n",
    "    percentages.append(df.iloc[-1][\"dup\"]*100/df.iloc[-1][\"reads\"])\n",
    "    \n",
    "    # find the maximum value of \"reads\"\n",
    "    max_temp=df[\"reads\"].max()\n",
    "    if max_temp>maxim: maxim=max_temp;\n",
    "    \n",
    "    # plot the data as a line plot using seaborn\n",
    "    ax = sns.lineplot(x=\"reads\", y=\"dup\", data=df,err_style='band',color=colours[n], label=sample, linewidth=1, alpha=0.8)\n",
    "    n=n+1\n",
    "\n",
    "# set the x and y limits of the plot\n",
    "ax.set(ylim=(0,maxim))\n",
    "ax.set(xlim=(0, maxim))\n",
    "\n",
    "# set the x and y labels of the plot\n",
    "ax.set_xlabel(\"Million reads\")\n",
    "ax.set_ylabel(\"PCR duplicates (Million reads)\")\n",
    "\n",
    "# add a legend to the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# save the plot as png and svg files\n",
    "ax.figure.savefig(output_supperdedupper_png, format=\"png\", bbox_inches = \"tight\",transparent=True)\n",
    "ax.figure.savefig(output_supperdedupper_svg, format=\"svg\", bbox_inches = \"tight\",transparent=True)\n",
    "\n",
    "# create a dataframe to store the percentage of duplicates for each sample\n",
    "pcr_dup_df=pd.DataFrame()\n",
    "pcr_dup_df[\"sample\"]=SAMPLES\n",
    "pcr_dup_df[\"pcr_percent_duplicates\"]=percentages\n",
    "\n",
    "# generate a styled HTML table of the dataframe and save it to a file\n",
    "pcr_dup_df_out=pcr_dup_df.style.background_gradient(cmap=\"RdYlGn_r\", vmin=0, vmax=100).render()\n",
    "with open(output_supperdedupper_html,\"w\") as fp:\n",
    "    fp.write(pcr_dup_df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff67625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the styled dataframe in the notebook\n",
    "pcr_dup_df.style.background_gradient(cmap=\"RdYlGn_r\", vmin=0, vmax=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
