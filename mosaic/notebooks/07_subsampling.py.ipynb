{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931514b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T09:15:26.742785Z",
     "iopub.status.busy": "2023-06-19T09:15:26.740536Z",
     "iopub.status.idle": "2023-06-19T09:15:26.753732Z",
     "shell.execute_reply": "2023-06-19T09:15:26.751710Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_dir=snakemake.params.mapping_dir\n",
    "clean_dir=snakemake.params.clean_dir\n",
    "sampling=snakemake.params.sampling\n",
    "qc_read_counts=snakemake.input.df_counts_paired\n",
    "SAMPLES=list(snakemake.params.samples)\n",
    "SAMPLES_sub_file=snakemake.input.key_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6ce8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T09:15:26.769559Z",
     "iopub.status.busy": "2023-06-19T09:15:26.767402Z",
     "iopub.status.idle": "2023-06-19T09:15:41.744033Z",
     "shell.execute_reply": "2023-06-19T09:15:41.741071Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "\n",
    "#------------------------------------------\n",
    "#Create a list of colors\n",
    "colors_rarefaction=sns.color_palette(\"colorblind\", n_colors=len(list(snakemake.params.samples)))\n",
    "#Create a LinearSegmentedColormap object\n",
    "cmap1=LinearSegmentedColormap.from_list(\"my_colormap\", sns.color_palette(\"colorblind\", n_colors=5))\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\",{'axes.grid' : True})\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.5\n",
    "plt.rcParams[\"xtick.major.width\"] = 1.5\n",
    "plt.rcParams[\"ytick.major.width\"] = 1.5\n",
    "plt.rcParams[\"xtick.major.size\"] = 8\n",
    "plt.rcParams[\"ytick.major.size\"] = 8\n",
    "plt.rcParams[\"axes.titlepad\"] = 20\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams[\"axes.titlesize\"] = 30\n",
    "plt.rcParams['axes.labelsize'] = 23.5\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Liberation Sans']\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams[\"savefig.dpi\"]=300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0b863",
   "metadata": {},
   "source": [
    "# Calculate mapping statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2817a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-19T09:15:41.764507Z",
     "iopub.status.busy": "2023-06-19T09:15:41.761729Z",
     "iopub.status.idle": "2023-06-19T09:15:44.762852Z",
     "shell.execute_reply": "2023-06-19T09:15:44.759133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data from qc_read_counts into a DataFrame\n",
    "df_counts_paired = pd.read_csv(qc_read_counts, index_col=0)\n",
    "\n",
    "# Select columns \"sample\" and \"bbduk\" from df_counts_paired\n",
    "reads_df = df_counts_paired[[\"sample\", \"bbduk\"]]\n",
    "\n",
    "# Create a new column \"bbduk2\" in reads_df, using a lambda function to calculate the minimum value between 2000000 and each value in \"bbduk\"\n",
    "reads_df['bbduk2'] = reads_df['bbduk'].apply(lambda x: min(2000000, x))\n",
    "\n",
    "# Rename columns in reads_df\n",
    "reads_df.columns = [\"sample\", \"read_count\", \"bbduk2\"]\n",
    "\n",
    "# Initialize empty lists\n",
    "mapped_pair_f = []\n",
    "mapped_pair_u = []\n",
    "mapped_pair_v = []\n",
    "mapped_pair_a = []\n",
    "mapped_pair_4 = []\n",
    "\n",
    "# Iterate over SAMPLES\n",
    "for sample in SAMPLES:\n",
    "    # Read content from files into corresponding lists\n",
    "    content_f = open(mapping_dir + \"/bowtie2_flagstats_filtered_\" + sample + \".\" + sampling + '.txt').readlines()\n",
    "    content_u = open(mapping_dir + \"/STATS_FILES/bowtie2_flagstats_filtered_\" + sample + \"_unfiltered_contigs.\" + sampling + '.txt').readlines()\n",
    "    content_v = open(mapping_dir + \"/STATS_FILES/bowtie2_flagstats_filtered_\" + sample + \"_viral_contigs.\" + sampling + '.txt').readlines()\n",
    "    content_a = open(mapping_dir + \"/STATS_FILES/bowtie2_flagstats_filtered_\" + sample + \"_assembled_contigs.\" + sampling + '.txt').readlines()\n",
    "\n",
    "    # Append calculated values to the respective lists\n",
    "    mapped_pair_f.append(int(content_f[1].split()[0]) / 2)\n",
    "    mapped_pair_u.append(int(content_u[1].split()[0]) / 2)\n",
    "    mapped_pair_v.append(int(content_v[1].split()[0]) / 2)\n",
    "    mapped_pair_a.append(int(content_a[1].split()[0]) / 2)\n",
    "\n",
    "# Create a new DataFrame df_mapped\n",
    "df_mapped = pd.DataFrame()\n",
    "df_mapped[\"sample\"] = SAMPLES\n",
    "df_mapped[\"mapped_f\"] = mapped_pair_f\n",
    "df_mapped[\"mapped_u\"] = mapped_pair_u\n",
    "df_mapped[\"mapped_v\"] = mapped_pair_v\n",
    "df_mapped[\"mapped_a\"] = mapped_pair_a\n",
    "\n",
    "# Merge df_mapped with reads_df based on the \"sample\" column\n",
    "df_mapped = df_mapped.merge(reads_df, left_on=\"sample\", right_on=\"sample\")\n",
    "\n",
    "# Calculate \"% assembled\", \"% viral\", \"% unfiltered\", and \"% filtered\" based on the merged DataFrame columns\n",
    "df_mapped[\"% assembled\"] = df_mapped[\"mapped_a\"] * 100 / df_mapped[\"bbduk2\"]\n",
    "df_mapped[\"% viral\"] = df_mapped[\"mapped_v\"] * 100 / df_mapped[\"bbduk2\"]\n",
    "df_mapped[\"% unfiltered\"] = df_mapped[\"mapped_u\"] * 100 / df_mapped[\"bbduk2\"]\n",
    "df_mapped[\"% filtered\"] = df_mapped[\"mapped_f\"] * 100 / df_mapped[\"read_count\"]\n",
    "\n",
    "# Calculate additional columns based on the merged DataFrame columns\n",
    "df_mapped[\"filtered-viral\"] = df_mapped[\"% filtered\"] - df_mapped[\"% viral\"]\n",
    "df_mapped[\"filtered-unfiltered\"] = df_mapped[\"% filtered\"] - df_mapped[\"% unfiltered\"]\n",
    "\n",
    "# Drop unnecessary columns from df_mapped\n",
    "df_mapped = df_mapped.drop([\"mapped_f\", \"mapped_u\", \"mapped_v\", \"mapped_a\", \"bbduk2\"], axis=1)\n",
    "\n",
    "# Round values in df_mapped to 1 decimal place\n",
    "df_mapped = df_mapped.round(1)\n",
    "\n",
    "# Display the styled DataFrame without writing to a file\n",
    "df_mapped.style.set_precision(2).background_gradient(cmap=\"RdYlGn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4099e",
   "metadata": {},
   "source": [
    "# Subsample reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAMPLES_sub_file) as f:\n",
    "    SAMPLES_sub = f.readlines()\n",
    "SAMPLES_sub = [x.strip() for x in SAMPLES_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsample=df_mapped.copy()[[\"sample\", \"read_count\",\"% filtered\"]]\n",
    "df_subsample[\"viral_reads\"]=df_subsample[\"read_count\"]*df_subsample[\"% filtered\"]/100\n",
    "# df_subsample[]\n",
    "filtered_df_subsample = df_subsample[df_subsample['sample'].isin(SAMPLES_sub)]\n",
    "viral_reads=int(filtered_df_subsample[\"viral_reads\"].min())\n",
    "print(viral_reads)\n",
    "\n",
    "df_subsample[\"subsample\"]=round(viral_reads*100/df_subsample[\"% filtered\"])\n",
    "\n",
    "\n",
    "for index, row in df_subsample.iterrows():\n",
    "    sample_value = row[\"sample\"]\n",
    "    sampling_data = row[\"subsample\"]\n",
    "    \n",
    "    # Create a file with the \"sample\" column value as the filename\n",
    "    filename = f\"{clean_dir}/{sample_value}_sub_sampling_reads.txt\"\n",
    "    \n",
    "    # Write the \"sampling\" data to the file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(str(int(sampling_data)))\n",
    "    \n",
    "\n",
    "df_subsample.sort_values(by=\"viral_reads\").style.set_precision(2).background_gradient(cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subsample[df_subsample[\"read_count\"]<df_subsample[\"subsample\"]][\"sample\"].to_list()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
